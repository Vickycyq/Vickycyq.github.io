[{"content":"\u0026ldquo;Zero-Shot Prompting\u0026quot;也称为“零样本提示”，是指在机器学习和自然语言处理中的一种技术，用于解决模型在处理未曾见过的、未经训练的类别或者数据时的问题。传统的机器学习模型需要在训练阶段接触到每个类别的数据样本，然后才能对其进行分类或者执行其他任务。但是，通过零样本提示，模型可以利用先前学习到的知识来完成该任务。\n例如，在自然语言处理中，如果模型已经训练了大量词汇，但是在测试的时候遇到了一个新的词汇，零样本提示可以让模型通过词汇的词义、上下文或者其他信息来推测该新词汇的含义，而不需要提供新词汇的训练样本。\n以下是零样本提示的使用示例：\n将文本分类为中性、负面、正面。 文本： 就这么点，不知道的还以为我要求的。少得可怜，我自己做都比这个多，这么点东西好意思收我60。 情感： ChatGPT输出：\n根据提供的文本，可以将其情感分类为负面。 这段文本表达了对某项要求的不满和对提供的服务或产品的不满意。 在这个例子中，我没有告诉ChatGPT什么样的文本是中性、负面或者正面，但是ChatGPT能正确对文本进行分类。\nWei et al.(2021)的研究采用了一个包含1370亿个参数的预训练模型，并在60多个自然语言指令模版下描述的NLP数据集上进行了instruction tune,并将instruction-tuned model称为FLAN。从下面的图片可以看出，instruction-tuning能有效提高语言模型的zero-shot学习能力。\nInstruction-tuning是一种微调大型预训练语言模型的方法，可以让模型根据特定任务提供指令来执行任务。 Fine-tuning和instruction tuning以及Prompt-tuning的区别：\nFine-tuning 是指采用预训练的模型（通常是在大规模数据上进行预训练的模型，如BERT、GPT等）作为初始模型，然后在特定任务的小规模数据上进行进一步训练。这种方法允许将大型通用模型迁移到特定任务上，以适应特定的数据和任务需求。 Instruction tuning模型不仅接受任务数据，还接受一种被称为\u0026quot;指导\u0026quot;或\u0026quot;说明\u0026quot;的自然语言输入，以帮助模型更好地适应特定任务。 Prompt tuning中，任务描述或提示文本（prompt）被设计成模型输入的一部分,是一种用于改善任务性能的技术,通常用于问答和文本生成任务。 Fine-tuning 是一种通用的微调方法，而instruction tuning 是fine-tuning 的一种变种，它利用自然语言指导来指导模型在特定任务上的微调，从而提高模型的性能。Instruction tuning 的关键优势在于它可以更灵活地适应多样的任务和指导。 当零样本提示不起作用时，可以适当在提示中提供演示或者示例，这种提示方式称为少样本提示。下一节将介绍少样本提示。\n","permalink":"https://vickycyq.github.io/zh/posts/blog/prompt-engineering/2-%E6%96%87%E6%9C%AC%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8A%80%E6%9C%AF/1-%E9%9B%B6%E6%A0%B7%E6%9C%AC%E6%8F%90%E7%A4%BA/","summary":"\u0026ldquo;Zero-Shot Prompting\u0026quot;也称为“零样本提示”，是指在机器学习和自然语言处理中的一种技术，用于解决模型在处理未曾见过的、未经训练的类别","title":"Zero-Shot Prompting"},{"content":" 战略决策主题规划复盘与思考 方法论： 通过企业《市场洞察及策略研讨资料》、《年度经营计划》、《年度预算编制》、季度经营分析会议材料等厘清企业战略决策全生命旅程的各个环节，结合 “五看三定” 模型以及DSTE框架对各个环节进行关键绩效指标梳理，根据关键绩效指标形成业务分析主题看板 管理驾驶舱规划可结合公司战略目标按照价值链排列方式设计，在数据监控过程中可沿着价值链方向根据数据异常发现业务问题 复盘与思考： 在项目实施过程中发现某个目标（指标A）设置的数值不合理。在与一线业务人员沟通的过程中发现，业务人员如果把精力放在完成指标A上，以指标A的目标数量，如果人员安排合理，指标B的数量将会是现在的目标的4倍。但是按照企业目前的情况，指标B的完成应该放在第一位，并且年度完成的结果可能只是指标B目标的一点几倍。显然指标A设置的数值过高，一线业务人员如果要完成指标A必然需要耗费大量精力，而无暇顾及目前集团最重视的指标B，企业应该理清指标A与指标B之间的关系，降低指标A的目标，让一线业务人员在完成指标B的情况下也能完成指标A 1. 战略决策业务框架及业务闭环思路 通过拆解战略决策全生命旅程，结合华为“五看三定”模型以及DSTE框架，构建战略决策业务分析框架，对各个环节分析内容展开，形成战略决策主题分析框架 1.1 战略决策全生命旅程 战略规划 市场洞察 战略分析与规划 经营执行与评估 经营目标 经营策略 经营计划 经营预算 绩效考核 1.2 五看三定 战略洞察 通过五看的方式（看宏观、看市场、看用户、看竞争、看自己），分析消费趋势，寻找与竞争对手的差距点以及行业机会点。（注：华为原五看为看行业/趋势、看市场/客户、看竞争、看自己、看机会，根据实际情况修改） 宏观环境分析（PEST为经典模型，但可根据实际情况增删内容）： 经济分析：通过GDP、投资、零售、货币政策等重点指标分析经济发展周期，查看经济周期与该行业发展周期的关系；根据当前经济周期调整长期战略；例如繁荣期扩大市场份额和投资，衰退期降本增效 消费分析：通过通货膨胀（CPI）=M2增速-GDP增速、CPI、PPI指标，分析经济热度；通过对比CPI与产品价格，分析经济热度，指导公司明确未来价格提升幅度与策略（跑赢通胀是基础），尤其是高端产品 收入分析：各省人均可支配收入情况，人均可支配收入增速，同时对比该区域订单收入增速；通过分析各省市经济状况和销售形势与方向，重点关注订单收入增速落后区域 人口分析：通过分析人口及其年龄结构变化，分析适饮/吃/用人口数量变化趋势根据年龄结构有助于产品目标市场定位、店铺选址、广告和宣传策略等 行业分析： 市场分析：通过波士顿矩阵查看公司/品牌在市场中的位置，根据分析结果分配资源或者制定不同产品的战略定位；或者通过价格带分析不同价格带产品/品牌市场份额或者订单收入或者其他指标、同比增速等等，洞察哪个价格带未部署产品或者哪个价格带有更大的切入机会；进一步对优势品牌进行分析，以寻找本品与竞品差异点 消费者分析：通过研究消费者交互数据、人口数据、行为数据、交易数据等挖掘消费者的关注点，从而找到产品差异化机会点 竞争态势分析：可使用波特五力模型作为研究框架，结合行业集中度、竞争对手的市场概况、商业模式、产品策略等，寻找本品与竞品差异点，看是否有新的商业机会 内部分析：通过对内部产品经营状况分析、产品竞争力以及内部运营分析，寻找内部优势，例如技术优势等 战略分析与规划 通过“三定”的方式（定控制点、定目标、定策略）制定企业战略规划； 战略控制点：指公司核心竞争力所在，这种竞争优势很难轻易形成，竞争对手也难以轻易赶上。比如成本优势、性能和品质的领先、绝对的市场份额、专利技术等； 定目标：达标目标（自上而下）+挑战目标（自下而上）； 定策略：制定具体方案和阶段里程碑、实施策略 战略分解 战略分解也称为战略解码，指的是分析和理解一个组织、企业或项目的战略计划、愿景和目标，以便将这些战略目标转化为具体的行动步骤和决策，战略解码工作可以采用BEM（Business strategy execution model）业务战略执行模型进行 BEM通过对战略逐层逻辑解码，导出可衡量和管理战略的KPI以及可执行的重点工作和改进项目/任务，并采用系统有效的运营管理方法，确保战略目标达成。BEM方法核心是PDCA模型，通过PDCA确保规划可落地 1.3 DSTE框架 DSTE概念：全称Develop strategy to execution，从战略到执行 战略规划流程（SP，Strategy Plan） 明确战略及战略描述：战略是为了牵引组织达成中长期目标的一系列行动而给出的指导方向性的、全局的谋略，是基于对未来的判断。对战略的描述应该具体可衡量。这一步可以使用BLM模型导出。 识别中长期关键战略举措（KSF）:根据业务要求，系统性分析战略布局，找出影响战略成功的关键因素，概括战略实现的具体措施 通过对商业模式的正确定义，应用Business Model Canvas设定战略方向，并进行mapping。商业模式描述了企业如何创造价值，传递价值和获取价值的基本原理 战略地图：描述组织如何创造价值，为战略制定和战略执行之间的鸿沟搭起一座桥梁。战略地图是平衡计分卡基础上发展而来的，是以平衡计分卡的四个层面目标（财务层面、客户层面、内部层面、学习层面）为核心，通过分析这四个层面目标的相互关系而绘制的企业战略因果关系图 导出战略衡量指标：可以使用IPOOC方法 年度业务规划（BP，Business Plan） 确定年度关键业务举措及目标：年度业务关键措施是指从客户与经营角度，为了支持战略达成的当年业务需要改进的关键点，业务关键措施针对业务和短板/痛点可能每年有所不同 分解年度关键业务举措和目标：沿着流程或者部门，将一层组织的业务关键措施和目标分解到下级部门，并从上至下，确定各层衡量指标的基线和目标值 确定年度重点工作：年度重点工作指的是关键战略措施在当年的具体措施，包括行动、阶段性目标、责任部门，是优先的工作任务 基于年度业务关键措施和目标拉通整合形成重点工作，设定工作目标及owner； 重点工作描述是针对战略举措要在当年落地的工作 重点工作目标主要承接战略举措在第一年的目标、组织KPI指标，从上至下结构化分解，确定各层衡量指标和值 战略执行监控与战略评估 战略执行监控 战略目标管理工具：为了战略有效得到执行和闭环，在组织绩效目标中设置“战略目标”，牵引各组织加强对战略机会点的有效投入，对当期业务结果负责的同时要对中长期持续发展负责 运营仪表盘工具：掌握SP/BP落地情况，并进行闭环管理 ","permalink":"https://vickycyq.github.io/zh/posts/blog/%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%9B%98%E4%B8%8E%E6%80%9D%E8%80%83/%E6%88%98%E7%95%A5/","summary":"战略决策主题规划复盘与思考 方法论： 通过企业《市场洞察及策略研讨资料》、《年度经营计划》、《年度预算编制》、季度经营分析会议材料等厘清企业战略","title":"战略决策分析框架建立与思考"},{"content":"在完成更复杂的任务时，零样本提示表现不佳，此时可以使用少样本提示（few-shot prompting），启用in-context learning，通过为模型提供demonstration引导模型实现更好的性能。\n“Few-Shot Learning\u0026quot;是指机器学习或深度学习中的一种训练策略，其中模型在处理训练数据时只使用非常有限数量的样本或示例。模型通过仅使用少量样本来学习任务，从而更好地泛化到未见过的数据。这对于许多应用场景非常重要，特别是在数据稀缺的情况下，例如医疗诊断、自然语言处理中的语言翻译等领域。 “Few-Shot Prompting\u0026quot;是一种用于预训练语言模型的技术，旨在将模型引导到执行特定任务的方式.“少样本”通常表示提示的信息非常有限，但是模型能根据这个提示来生成答案或执行任务. zero-shot和one-shot对比示例：\n输入：\n请用farduddle这个词造句 ChatGPT输出：\n他在寒风中等待了一个小时，完全感到了冷到了骨子里，但他坚持在那里farduddle着，直到朋友终于出现了。 可以看出，ChatGPT并没有理解这个单词，因此造出来的句子词不达意。接下来用 Brown et al.（2020）的例子做one-shot prompting。 输入：\n“whatpu”是坦桑尼亚的一种小型毛茸茸的动物。一个使用whatpu这个词的句子的例子是： 我们在非洲旅行时看到了这些非常可爱的whatpus。 “farduddle”是指快速跳上跳下。一个使用farduddle这个词的句子的例子是： ChatGPT输出：\n孩子们在操场上高兴地farduddle着，玩得不亦乐乎。 在这个例子中，我们给了ChatGPT一个demonstration，ChatGPT已经能根据给的demonstration执行任务，对于更困难的任务，可以增加demonstration的个数（5-shot, 10-shot）。\nZhao et al.(2021)的论文指出：\ndemonstration的format很重要，即使只是使用随机标签，模型的performance也比没有标签好 demonstration的input的分布对模型的in-context learning性能影响很大，而label space的分布则不重要 而另一篇论文则有不完全相同的研究结论，Min et al., (2022)的论文则指出：\nlabel space和demonstration的输入文本的分布都很重要（标签是否正确） 使用的格式也对性能起着关键作用，即使只是使用随机标签，这也比没有标签好得多 其他结果表明，从真实标签分布（而不是均匀分布）中选择随机标签也有帮助 我们给下面的外卖评论分配随机标签，看ChatGPT能否正确完成任务： 输入：\n这家分店的五分糖巨甜！！！比我喝过的其他店的都甜很多//负面 今天的要么太咸，要么太淡，牛肉还没烤干，都丢了没吃//正面 吃过很多次了，连带淄博小饼套餐，很喜欢烤牛肉和鸡翅//负面 记不清第几次点了，好吃太好吃了，简直是本干饭人心中的白月光// ChatGPT输出：\n最后一个评论非常正面，表达了对食物的喜爱。 可以看出，即使给评论分配错误的标签，ChatGPT还是正确完成了任务\n执行更复杂的任务时，少样本提示的作用不大 输入：\nA、B是两个长方体物块，叠放在水平地面C上，A叠放在B上，F是作用在物块B上沿水平方向右的力，大小为200N，物块A和B以相同的速度做匀速直线运动，由此可知，关于A、B间摩擦力F1为0N，B、C间摩擦力为200N。 A：答案是True 水平地面上叠放A、B两个物体，A在B上面，A、B大小一样，给A施加一个向右的拉力F1=5N，给B施加一个向左的拉力F2=3N，那么物体B的上下表面所受到摩擦力的大小为5N和3N A：答案是False 水平面上叠放着A、B两个物体，A在B上面，在水平方向力F的作用下，相对静止，一起向左做匀速直线运动，已知F=5N，物体B上下表面所受摩擦力分别是5N和5N A： ChatGPT输出：\n在水平面上叠放A、B两个物体，它们以相同的速度做匀速直线运动，外力F=5N。因为它们以相同的速度运动，A、B之间的摩擦力应该平衡外力F，所以它们之间的摩擦力都是5N。这个陈述是True。 显然，ChatGPT给出了错误的答案，因为完成这个任务需要涉及更多的推理步骤，所以需要更高级的prompting技术，比如将步骤写成demonstration提示AI从而完成任务，下一节将介绍Chain-of-Though Prompting.\n","permalink":"https://vickycyq.github.io/zh/posts/blog/prompt-engineering/2-%E6%96%87%E6%9C%AC%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8A%80%E6%9C%AF/2-%E5%B0%91%E6%A0%B7%E6%9C%AC%E6%8F%90%E7%A4%BA/","summary":"在完成更复杂的任务时，零样本提示表现不佳，此时可以使用少样本提示（few-shot prompting），启用in-context learni","title":"Few-Shot Prompting"},{"content":"\u0026ldquo;Chain-of-Thought Prompting\u0026quot;是指在demonstration中设计一系列连贯的思维步骤从而引导模型在面对复杂的推理任务时，将问题分解成多个中间步骤，并逐一解决，然后给出最后的答案。\n在CoT提出之前，关于大规模语言模型的推理任务中，有两种方法，一是针对下游任务对模型进行微调，但是微调成本高；二是为模型提供少量输入输出样例进行学习，传统的输入输出样例在推理任务上效果比较差。针对这个问题，Wei et al. (2022)提出Chain-of-Thought这种提示技术: 上图展示了few-shot prompting和chain of thought prompting方法求解推理任务的对比，few-shot prompting在推理任务中表现并不好 而CoT在demonstration中不仅给出了答案，还人为写出了中间的推理步骤。给出了根据CoT方式写的demonstration后，语言模型会自动先根据任务写出中间推理步骤，根据步骤给出正确答案 作者还在论文中提到了以下几点：\nCoT是将一个多步骤的复杂推理任务分解出中间步骤，而语言模型在输出的时候是一个一个token进行生成的，因此问题越难，步骤越多，生成的token数量就越多，因此越难的问题使用到的计算量就越大，计算机分配的计算资源也越多 在不知道答案的情况下，用CoT能同时知道中间推理步骤 接下来让我们使用CoT来解决上一节的推理问题： 输入：\nA、B是两个长方体物块，叠放在水平地面C上，A叠放在B上，F是作用在物块B上沿水平方向右的力，大小为200N，物块A和B以相同的速度做匀速直线运动，由此可知，关于A、B间摩擦力F1为0N，B、C间摩擦力为200N。 A：由于物块A和B以相同的速度做匀速直线运动，因此A受力平衡，合力为0，A不受摩擦力，所以A与B之间的摩擦力F1为0N；物块B受水平向右的力200N，同时以相同的速度做匀速直线运动，合力为0，因此物块B受水平向左的摩擦力200N，BC间的摩擦力为200N，答案是True 水平地面上叠放A、B两个物体，A在B上面，A、B大小一样，给A施加一个向右的拉力F1=5N，给B施加一个向左的拉力F2=3N，那么物体B的上下表面所受到摩擦力的大小为5N和3N A：由于物块A和B同时以相同的速度做匀速直线运动，因此A、B的合力均为0，A受向右的拉力5N，所以AB之间有向左的摩擦力5N；B受向左的拉力3N，向右的与A之间的摩擦力5N，因此B与地面之间的摩擦力是向左的2N，答案是False 水平面上叠放着A、B两个物体，A在B上面，在水平方向力F的作用下，相对静止，一起向左做匀速直线运动，已知F=5N，物体B上下表面所受摩擦力分别是5N和5N A： ChatGPT输出：\n对于第三个情况，答案可能是 False。物块 B 与地面之间的摩擦力应该受到施加在 B 上的力 F=5N 的影响，但具体的摩擦力大小取决于物块 B 和地面之间的摩擦系数。如果摩擦系数足够大，以至于可以平衡施加在 B 上的力 F=5N，那么 B 与地面之间的摩擦力可能为 5N。但如果摩擦系数较小，不能完全平衡力 F，那么摩擦力可能小于 5N。所以答案会取决于具体的摩擦系数值。 从上面的回答可以看出，ChatGPT给出了正确的答案，但是还是没有完全把A和B的受力情况答对。\nZero-shot-CoT：\n上面我们写的例子是mannual-CoT,即在输入问题前，手动设计一些问题和答案的样例，同时给出中间推理步骤，因此我认为在这种方式下，设计有代表性的样例和推理步骤比较重要。 而zero-shot-CoT就是在输入问题的时候，连接“let\u0026rsquo;s think step by step\u0026quot;让语言模型自动续写推理步骤，并最终生成答案。 我们看看以下例子：\n输入：\n水平面上叠放着A、B两个物体，A在B上面，B在水平方向力F的作用下，相对静止，一起向左做匀速直线运动，已知F=5N，物体B下表面与地面之间的摩擦力5N，A与B之间的摩擦力是0N，这是正确的吗？let's think step by step A： ChatGPT输出：\n物体 B 处于水平面上，所以有地面对物体 B 的支持力（垂直向上）以及重力（垂直向下）。由于物体 B 相对静止，这两个力必须平衡。 物体 B 与地面之间的支持力等于物体 B 的重力，这可以用牛顿的第三定律解释。支持力等于物体 B 对地面的作用力，也等于地面对物体 B 的反作用力，它们大小相等。 物体 B 在水平方向上受到外力 F=5N 的作用，这是一个向左的力。 由于物体 B 相对静止，水平方向上的外力 F 必须由摩擦力来平衡，以防止物体 B 滑动。 物体 A 在物体 B 上，如果 A 与 B 之间没有水平方向上的相对运动，那么它们之间的摩擦力应该是零。 综上所述，物体 B 下表面与地面之间的摩擦力是 5N，以防止它滑动，而 A 与 B 之间的摩擦力是零，因为它们之间没有相对运动。所以，这个情况是正确的。 从上面的例子可以看出，ChatGPT通过“let\u0026rsquo;s think step by step\u0026quot;这句话就能自动续写推理过程，并最终得出正确答案。在这个过程中，我曾修改了题目的描述，因此我认为清晰避免歧义的题目描述也有助于ChatGPT理解文本并按步骤推理。\nAuto-CoT：\nZhang et al.(2022)在论文中尝试使用Auto-CoT，即先把示例问题加上“let\u0026rsquo;s think step by step\u0026quot;这句话，让语言模型自动生成推理步骤，然后将示例加上生成的推理步骤以及答案拼接起来，构成few-shot样例，最后加上输入的问题让语言模型写中间推理步骤以及答案。 Active Prompt\n设计出针对特定任务的提示对语言模型生成高质量的答案的能力至关重要。从上文的研究可以看出，CoT prompting在针对复杂的问答推理任务时有比较好的表现，但是，目前的CoT方法依赖于人工标注的示例，而这些示例并不一定是适用于不同任务的最有效示例。因此，Diao et al.(2023)提出了一种名为Active-Prompt的方法。\n这种方法是指标来描述模型对每个问题预测的答案的不确定性，选出不确定性最大的一些问题，通过人工对这些问题用CoT的形式回答并加上测试问题输入语言模型，以提高语言模型的性能。例如：对于数据集D中的问题，输入语言模型，每个问题询问K次，然后计算基于这些问题的回答的 uncertainty。选出uncertainty最大的n个问题，并且对这些问题人工标注答案，作为example。然后用这些example加到每个测试问题中，按照CoT的方法提示。 对于uncertainty的衡量，论文给出以下四点： Disagreement：询问k次生成的k个答案中，相同答案出现的次数h的占比，即u=h/k Entropy：用下图的公式计算，熵越大，不确定性越大 Variance： Self-Confidence： 下图是实验结果： 从上图的实验结果可以看出来，跟baseline model相比，Active-Prompt这种方法让模型的performance更好了。 Self Consistancy Wang et al.(2023)在论文中提出了一种名为”Self Consistancy“的decoding策略来取代CoT方法的naive greedy decoding。\nNaive greedy decoding是一种简单且直接的解码方法，通常用于生成式任务。在这种解码方式中，模型会根据当前的输入和已生成部分的输出，选择概率最高的下一个单词或者符号作为预测结果，它只考虑当前最高的概率的单词或者符号，而不考虑后续的选择如何影响整体生成序列的质量，因此不能保证生成的整体序列在语法或者语义上是合理的。 从上图可以知道，self consistancy有三个步骤： （1）用CoT提示语言模型 （2）从语言模型的解码器中采样，生成一系列不同的推理路径 （3）剔除推理路径，在最终答案中选择最一致的答案 从上图结果可以看出，self consistancy的performance比CoT好。 我们来用这种方法试试前面提到的例子： 输入：\n1.水平面上叠放着A、B两个物体，A在B上面，B在水平方向力F的作用下，相对静止，一起向左做匀速直线运动，已知F=5N，物体B下表面与地面之间的摩擦力5N，A与B之间的摩擦力是0N，这是正确的吗？ A：物体 B 处于水平面上，所以有地面对物体 B 的支持力（垂直向上）以及重力（垂直向下）。由于物体 B 相对静止，这两个力必须平衡。 物体 B 与地面之间的支持力等于物体 B 的重力，这可以用牛顿的第三定律解释。支持力等于物体 B 对地面的作用力，也等于地面对物体 B 的反作用力，它们大小相等。 物体 B 在水平方向上受到外力 F=5N 的作用，这是一个向左的力。 由于物体 B 相对静止，水平方向上的外力 F 必须由摩擦力来平衡，以防止物体 B 滑动。 物体 A 在物体 B 上，如果 A 与 B 之间没有水平方向上的相对运动，那么它们之间的摩擦力应该是零。 综上所述，物体 B 下表面与地面之间的摩擦力是 5N，以防止它滑动，而 A 与 B 之间的摩擦力是零，因为它们之间没有相对运动。所以，这个情况是正确的。 2.水平地面上叠放A、B两个物体，A在B上面，A、B大小一样，给A施加一个向右的拉力F1=5N，给B施加一个向左的拉力F2=3N，那么物体B的上下表面所受到摩擦力的大小为5N和3N A：由于物块A和B同时以相同的速度做匀速直线运动，因此A、B的合力均为0，A受向右的拉力5N，所以AB之间有向左的摩擦力5N；B受向左的拉力3N，向右的与A之间的摩擦力5N，因此B与地面之间的摩擦力是向左的2N，答案是False 3.A、B是两个长方体物块，叠放在水平地面C上，A叠放在B上，F是作用在物块B上沿水平方向右的力，大小为200N，物块A和B以相同的速度做匀速直线运动，由此可知，关于A、B间摩擦力F1为0N，B、C间摩擦力为200N。 A： ChatGPT输出1：\n对于第三个情况，让我们仔细考虑一下： 物块 B 受到水平方向上的外力 F = 200N 的作用，这是一个向右的力。 物块 B 处于水平面上，所以有地面对物块 B 的支持力（垂直向上）以及重力（垂直向下）。由于物体 B 相对静止，这两个力必须平衡。 物块 B 与地面之间的支持力等于物块 B 的重力，这可以用牛顿的第三定律解释。支持力等于物体 B 对地面的作用力，也等于地面对物体 B 的反作用力，它们大小相等。 由于物体 B 相对静止，水平方向上的外力 F 必须由摩擦力来平衡，以防止物体 B 滑动。 所以，在这个情况下，物体 B 与地面之间的摩擦力应该是 200N，而物体 A 与 B 之间的摩擦力是 0N，因为它们之间没有相对运动。所以，这个情况是正确的。 ChatGPT输出2：\n水平面上叠放着 A、B 两个物体，A 在 B 上面，B 在水平方向受力 F 的作用下，相对静止，一起向左做匀速直线运动，已知 F=5N，物体 B 下表面与地面之间的摩擦力是 5N，A 与 B 之间的摩擦力是 0N。 物体 B 处于水平面上，所以有地面对物体 B 的支持力（垂直向上）以及重力（垂直向下）。由于物体 B 相对静止，这两个力必须平衡。 物体 B 与地面之间的支持力等于物体 B 的重力。 物体 B 在水平方向上受到外力 F=5N 的作用，这是一个向左的力。 由于物体 B 相对静止，水平方向上的外力 F 必须由摩擦力来平衡，以防止物体 B 滑动。 物体 A 在物体 B 上，如果 A 与 B 之间没有水平方向上的相对运动，那么它们之间的摩擦力应该是零。 综上所述，物体 B 下表面与地面之间的摩擦力是 5N，以防止它滑动，而 A 与 B 之间的摩擦力是零，因为它们之间没有相对运动。所以，这个情况是正确的。 ChatGPT输出3：\n让我们来分析第三种情况，即 A、B、C 三个物块的摩擦力情况： 物块 B 受到水平方向上的外力 F = 200N 的作用，这是一个向右的力。 物块 B 处于水平面上，所以有地面对物体 B 的支持力（垂直向上）以及重力（垂直向下）。由于物体 B 相对静止，这两个力必须平衡。 物块 B 与地面之间的支持力等于物块 B 的重力，这可以用牛顿的第三定律解释。支持力等于物体 B 对地面的作用力，也等于地面对物体 B 的反作用力，它们大小相等。 由于物体 B 相对静止，水平方向上的外力 F 必须由摩擦力来平衡，以防止物体 B 滑动。 关于摩擦力： A 与 B 之间的摩擦力：因为 A 和 B 相对静止，所以它们之间的摩擦力必须平衡外力 F。这意味着 A 和 B 之间的摩擦力应该是 200N，与外力 F 相等，以保持静止。 B 与 C 之间的摩擦力：由于 B 与 C 之间没有相对运动，它们之间的摩擦力应该是零。如果没有相对滑动，就不需要摩擦力来抵消外部力。 综上所述，关于 A、B 间的摩擦力 F1 为 200N 是正确的，而 B、C 间的摩擦力为 0N 也是正确的。 为了简单起见，我只用这个例子让ChatGPT输出3次，不同的推理步骤可以得到大多数一致的答案。\nMultimodal Chain-of-Thought\n现有的关于CoT的研究主要集中在language modality上，Zhang et al., (2023)提出将语言（文本）和视觉（图片）整合到一个两阶段的框架中，第一阶段是通过给模型输入文本和图片，模型根据输入内容输出中间推理过程；第二阶段是输入包含推理过程的问题文本以及图片，模型根据输入内容对结果进行推断。下图是Multimodal Chain-of-Thought这种方法的过程： 下图是实验结果： ","permalink":"https://vickycyq.github.io/zh/posts/blog/prompt-engineering/2-%E6%96%87%E6%9C%AC%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8A%80%E6%9C%AF/3-cot_prompting/","summary":"\u0026ldquo;Chain-of-Thought Prompting\u0026quot;是指在demonstration中设计一系列连贯的思维步骤从而引导模型在面对复杂的推理任务时，将问题分解成多","title":"Chain-of-Thought Prompting"},{"content":"Liu et al.(2022)的论文提出了“知识生成提示”这种方式，主要做法是（1）先用few-shot demonstration的方式从语言模型中生成与问题相关的知识，然后（2）使用第二个语言模型对每个知识进行预测，然后选择置信度好的预测。 下图是论文的结果： 接下来我们用论文里面的例子来演示这种方式：\n首先，我们不用任何技巧，直接询问ChatGPT\n输入：\n高尔夫球的一部分是试图获得比其他人更高的得分。是或否？ 输出：\n是的，高尔夫球的一部分是试图获得比其他人更低的得分，因为在高尔夫中，较低的得分代表着更好的表现。 显然，ChatGPT的回答与后面的解释前后矛盾。 用知识生成提示方法：\n首先用few-shot的方法生成一些知识：\n输入：希腊比墨西哥大。 知识：希腊的面积约为131,957平方公里，而墨西哥的面积约为1,964,375平方公里，使墨西哥比希腊大了1,389%。 输入：眼镜总是会起雾。 知识：当你的汗水、呼吸和周围的湿度中的水蒸气落在冷的表面上，冷却并变成微小的液滴时，会在眼镜镜片上产生冷凝。你看到的是一层薄膜。你的镜片相对于你的呼吸会比较凉，尤其是当外面的空气很冷时。 输入：鱼有思考能力。 知识：鱼比它们看起来更聪明。在许多领域，如记忆力，它们的认知能力与或超过非人类灵长类动物等“更高级”的脊椎动物。鱼的长期记忆帮助它们跟踪复杂的社交关系。 输入：一个人一生中吸烟很多香烟的常见影响是患肺癌的几率高于正常水平。 知识：那些一生中平均每天吸烟不到一支香烟的人，患肺癌的风险是从不吸烟者的9倍。在每天吸烟1到10支香烟之间的人群中，死于肺癌的风险几乎是从不吸烟者的12倍。 输入：一块石头和一颗卵石大小相同。 知识：卵石是一种根据Udden-Wentworth沉积学尺度的颗粒大小为4到64毫米的岩屑。卵石通常被认为比颗粒（直径2到4毫米）大，比卵石（直径64到256毫米）小。 输入：高尔夫球的一部分是试图获得比其他人更高的得分。 知识： 输出：\n高尔夫球的目标是以最少的杆数打完一组洞。一轮高尔夫球比赛通常包括18个洞。每个洞在标准高尔夫球场上一轮只打一次。每个杆计为一分，总杆数用于确定比赛的获胜者。 提示:\n问题：高尔夫球的一部分是试图获得比其他人更高的得分。是或否？ 知识：高尔夫球的目标是以最少的杆数打完一组洞。一轮高尔夫球比赛通常包括18个洞。每个洞在标准高尔夫球场上一轮只打一次。每个杆计为一分，总杆数用于确定比赛的获胜者。 解释和答案： 输出1（置信度非常高）：\n不是，高尔夫球的目标不是获得比其他人更高的得分。相反，目标是以最少的杆数打完一组洞。总杆数用于确定比赛的获胜者，而不是总得分。 答案2（置信度要低得多）：\n是的，高尔夫球的一部分是试图获得比其他人更高的得分。每个选手都试图以最少的杆数打完一组洞。总杆数用于确定比赛的获胜者，而不是总得分。得分最低的选手赢得比赛。 不过，在论文中作者也提到，在提示时加入外部知识这种方法的优势可能随着基础模型的规模和在更大量文本数据集上进行预训练而逐渐消失。\n","permalink":"https://vickycyq.github.io/zh/posts/blog/prompt-engineering/2-%E6%96%87%E6%9C%AC%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8A%80%E6%9C%AF/5-generated-knowledge-prompting/","summary":"Liu et al.(2022)的论文提出了“知识生成提示”这种方式，主要做法是（1）先用few-shot demonstration的方式从语言模型中","title":"Generated Knowledge Prompting"},{"content":"1.结论 2.数据清洗 3. ","permalink":"https://vickycyq.github.io/zh/posts/project/%E7%94%B5%E5%95%86%E9%94%80%E5%94%AE%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/","summary":"1.结论 2.数据清洗 3.","title":"电商销售数据可视化"},{"content":"","permalink":"https://vickycyq.github.io/zh/link/","summary":"","title":"🔗友链"}]