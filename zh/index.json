[{"content":"用户分析方法论及结论 用户分析方法论 结论 1.数据总览 import pandas as pd import numpy as np import matplotlib.pyplot as plt from datetime import datetime #忽略警告 import warnings warnings.filterwarnings('ignore') plt.rcParams['font.sans-serif'] = ['Heiti TC'] # 指定中文字体，例如使用中文宋体：['SimSun'] plt.rcParams['axes.unicode_minus'] = False # 解决负号显示为方块的问题 plt.rcParams['axes.unicode_minus'] = False #正常显示负号 df=pd.read_csv(\u0026quot;/Users/v***/Desktop/数据分析项目/某电子产品销售数据分析报告及RFM模型/电子产品销售分析.csv\u0026quot;) In[6]: df.head(6) 2.数据预处理 2.1日期处理 #获取日期 df['date']=df.event_time.apply(lambda x: x.split('')[0]) #使用空格作为分隔符，取第一部分作为date这一列的内容 df['date'] = pd.to_datetime(df['date']) #创建年、月、日、星期列 df['year'] = df.date.dt.year df['month'] = df.date.dt.month df['day'] = df.date.dt.day df['weekday'] = df.date.apply(lambda x: x.strftime('%w')) #创建时间列 df['hour'] = df.event_time.apply(lambda x: x.split(' ')[1].split(':')[0]) df.head(3) 2.2数据清洗（缺失值处理） #查看数据确实状态 df.info() 从结果可以看出，category_code和brand这两列有缺失值，category_code这一列缺失值比较多，用R来填充标记；brand这一列缺失值比较少，可以直接删除缺失值\ndf['category_code'] = df['category_code'].fillna('R') df['brand'] = df[df.brand.notnull()] 从上图结果可以看出，category_code和brand这两列已经没有缺失值了\n2.3新列增加 购买数量\n#根据user_id的数量确定order_id和product_id的数量，即一个人（user_id）一次订单（order_id)购买了多少个产品（product_id） df_buy_cnt = df.groupby(['order_id','product_id']).agg(buy_cnt=('user_id','count')) df_buy_cnt.head(2) #将df_buy_cnt和df两个表合并 df = pd.merge(df,df_buy_cnt,on=['order_id','product_id',how='inner']) df = df.frop_duplicates().reset_index(drop=true) print(df.head(2)) 购买金额\ndf['amount'] = df['price'] * df['buy_cnt'] print(df.head(2)) #把id转化为object df.order_id = df.order_id.astype('object') df.prouct_id = df.product_id.astype('object') df.category_id = df.category_id.astype('object') df.user_id = df.user_id.astype('object') #把hour和weekday转化为int df['hour'] = df.loc[:,'hour'].astype('int') df['weekday'] = df.loc[:,'weekday'].astype('int') df.info() 2.4异常值处理 #查看价格和年龄是否存在异常值，查看最大值最小值等 df.describe(percentiles=[0.01,0.25,0.75,0.99]).T 从上面图片的结果可以看出来，价格有0元，但是可能是因为有些消费者购买了免费商品，后面可以进一步分析购买了0元商品的用户是否有购买其他商品。\n#检查其他字段是否有异常值 df.describe(include='all').T 从上图结果可以看出，日期有异常值，需要把异常值删除\nIn[20]: df=df[df.date\u0026gt;'1970-01-01'] df.date.min() Out[20]: Timestamp('2020-01-05 00:00:00') 3.数据分析 3.1GMV In[22]: round(df['amount'].sum(),0) Out[22]: 115211898.0 月度GMV\ndf_GMV_month = df.groupby('month').agg(GMV=('amount','sum')) #创建一个包含子图的画布 fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8)) #绘制折线图 x = df_GMV_month['month'] y = df_GMV_month['GMV'] ax1.plot(x, y, marker='o', linestyle='-', color='yellow', label='GMV') ax1.set_xlabel('Month') ax1.set_ylabel('GMV') ax1.set_title('Monthly GMV') ax1.legend() #绘制表格 ax2.axis('tight') ax2.axis('off') table_data = df_GMV_month.reset_index() # 重置索引，以便包含 \u0026quot;month\u0026quot; 列 col_labels = table_data.columns.tolist() # 获取列标签 table_data = table_data.values.tolist() # 将数据转换为列表 table_data.insert(0, col_labels) # 将列标签插入到数据的开头 ax2.table(cellText=table_data, cellLoc='center', colLabels=None,cellColours=None, loc='center') plt.tight_layout() plt.show() 客单价\nIn[62]: AOV= round(df['amount'].sum()/df['user_id'].nunique(),0) Out[62]: 1242.0 订单数量\nIn[63]: order_cnt = df['order_id'].nunique() Out[63]: 388742 平均订单价\nIn[64]: round(df['amount'].sum()/order_cnt) Out[64]: 296 3.2用户分析 3.2.1用户数量 In[65]: df['user_id'].nunique() Out[65]: 92755 #各地区用户数量 local_user_num = df.groupby('local')['user_id'].nunique().reset_index() local_user_num = local_user_num.rename(columns={'user_id':'用户数量','local':'省份'}) local_user_num = local_user_num.sort_values('用户数量').reset_index(drop=True) fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 8)) #绘制条形图 x = local_user_num['省份'] y = local_user_num['用户数量'] ax1.bar(x,y,color='yellow',label='用户数量') ax1.set_xlabel('省份') ax1.set_ylabel('用户数量') ax1.set_title('各省份用户数量') ax1.legend() #绘制表格 ax2.axis('tight') ax2.axis('off') #local_user_table = local_user_num.reset_index() # 重置索引，以便包含 \u0026quot;month\u0026quot; 列 col_labels = local_user_num.columns.tolist() # 获取列标签 local_user_table = local_user_num.values.tolist() # 将数据转换为列表 local_user_table.insert(0, col_labels) # 将列标签插入到数据的开头 ax2.table(cellText=local_user_table, cellLoc='center', colLabels=None,cellColours=None, loc='center') plt.tight_layout() plt.show() #根据2020年的全国人口普查，在网上得到了各省的人口数量数据，分析各省用户的占比，看看哪些省还可以进行用户拉新 population = pd.read_excel(\u0026quot;/Users/v***/Desktop/数据分析项目/某电子产品销售数据分析报告及RFM模型/2020年各省人口数量.xlsx\u0026quot;) population = population.iloc[:,:2] population.head() local_user_num = pd.merge(local_user_num, population, how='inner', left_on='省份', right_on='地区') local_user_num['占比‘] = local_user_num['用户数量']/local_user_num['人口数'] local_user_num = local_user_num.sort_values('占比',ascending=False).reset_index(drop=True) local_user_num['占比'] = local_user_num['占比'].apply(lambda x: '{:.5f}%'.format(x)) local_user_num.head() 从上图中的占比可以看出，用户数量占比前三是北京/上海/海南，第四是天津，广东排第五，广东的占比仅为北京的1/5，而且广东人口数量是最多的，因此在广东进行拉新活动的性价比是最高的\n3.2.2用户结构 #用户性别分布 sex = df.groupby('sex')['user_id'].nunique().reset_index() sex.rename(columns={'user_id':'用户数量'},inplace=True) #用户年龄分布 bins = [15,20,25,30,35,40,45,50] labels = ['(15-20]岁','(20-25]岁','(25-30]岁','(30-35]岁','(35-40]岁','(40-45]岁','(45-50]岁'] df_copy=df.copy() df_copy['age_bin']=pd.cut(x=df.age,bins=bins,right=True,labels=labels) age = df_copy.groupby('age_bin)['user_id'].nunique().reset_index() age.rename(columns={'user_id':'用户数量','age_bin':'年龄段'},inplace=True) fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6)) #性别分布 ax1.pie(sex['用户数量'],labels=sex['sex'],autopct='%1.2f%%'，colors=['blue','yellow']) ax2.pie(age['用户数量'],labels=age['年龄段'],autopct='%1.2f%%') plt.show() 从上图结果可以看出，用户性别比例和各年龄段分布都比较均匀\n#各年龄段消费金额及下单数量 age_bin_amount = df_copy.groupby('age_bin').agg(消费金额=('amount','sum'),下单数量=('order_id','nunique')).reset_index() #各性别消费金额及下单数量 sex_amount = df_copy.groupby('sex').agg(消费金额=('amount','sum'),下单数量=('order_id','nunique')).reset_index() # fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2, 2, figsize=(16, 6)) fig,ax1=plt.subplots(figsize=(16,8)) xticks=np.arange(len(age_bin_amount.index)) # len(age_bin_amount.index) 返回了年龄段分组的数量 ax1.bar(xticks,age_bin_amount['消费金额'],width=0.3,color='g') ax1.set_xlabel('年龄段') ax1.set_ylabel('消费金额（百万元）') ax1.set_title('不同年龄段消费金额及下单次数') ax2 = ax1.twinx() #创建一个与 ax1 共享 x 轴但独立 y 轴的轴对象 ax2，通常用于绘制第二个 y 轴上的图表 ax2.bar(xticks+0.3,age_bin_amount['下单数量'],width=0.3,color='b') ax2.set_ylabel('下单次数（次）') ax1.set_xticks(xticks+0.15) ax1.set_xticklabels(age_bin_amount.index) #设置X轴坐标文字显示 fig,ax3=plt.subplots(figsize=(16,8)) xticks=np.arange(len(sex_amount.index)) ax3.bar(xticks,sex_amount['消费金额'],width=0.3,color='g') ax3.set_xlabel('性别') ax3.set_ylabel('消费金额（百万元）') ax3.set_title('不同性别消费金额及下单次数') ax4 = ax3.twinx() #创建一个与 ax1 共享 x 轴但独立 y 轴的轴对象 ax2，通常用于绘制第二个 y 轴上的图表 ax4.bar(xticks+0.3,sex_amount['下单数量'],width=0.3,color='b') ax4.set_ylabel('下单次数（次）') ax3.set_xticks(xticks+0.15) ax3.set_xticklabels(sex_amount.index) #设置X轴坐标文字显示 3.2.3购买了0元产品的用户 df[df['price']==0] #将购买了0元产品的用户提取出来 user_0 = df[df['price']==0]['user_id'].reset_index(drop=True) user_0.shape # (30,) user_0[~user_0.isin(df[df['price']\u0026gt;0]['user_id'])] #0 1515915625468531712.00 #Name: user_id, dtype: float64 从上面的结果可以看出，有30个用户购买了0元产品，30个用户中只有1个没有购买别的产品\ndf_user_0 = pd.merge(df,user_0,on='user_id') df_user_0_amount = df_user_0.groupby('user_id').agg(消费金额=('amount','sum')).sort_values('消费金额',ascending=False) df_user_0_amount.reset_index(inplace=True) #该批客户的客单价 df_user_0_amount['消费金额'].sum/30 #34832.36466666667 这批客户的客单价高达34832，因此做一些抽奖活动确实可以提高客单价\n3.2.4二八定律 二八定律\u0026ndash;找出累计贡献销售额80%的那批客户\nuser_28 = df.groupby('user_id').agg(消费金额=('amount','sum')).sort_values('消费金额',ascending=False).reset_index() user_28['累计销售额'] = user_28['消费金额'].cumsum() #创建累计占比，计算每个用户的累计销售额占总销售额的比例 p=user_28['消费金额'].cumsum()/user_28['消费金额'].sum key=p[p\u0026gt;0.8].index[0] #从累计占比 Series 中找到第一个满足累计占比大于 0.8 的索引位置，也就是第一个达到 80% 销售额的用户索引 key #25392 key/user_28.shape() #0.27375343647242734 从上面的结果可以看出，第一个达到80%的用户索引是25392，27%的用户贡献了销售额的80%，说明维护好这一批用户就能达到80%的销售额，这是大客户。\n#客户消费金额分位数 df.groupby('user_id').agg(消费金额=('amount','sum')).describe(percentiles=(0.01,0.1,0.25,0.75,0.9,0.99)).T 用户平均消费金额大于75%分位数,即存在着高消费的客户\n3.2.5客户消费周期 #x['date'] 表示当前购买记录的日期，而 x['date'].shift() 则表示上一次购买记录的日期，两者相减得到一个时间差。 #.dt.days：将上述时间差转换为天数，以便后续的分析和统计。 purchase_day = df[df['amount']\u0026gt;0].sort_values('date').groupby('user_id').apply(lambda x: x['date']-x['date'].shift()).dt.days purchase_day.reset_index() purchase_day purchase_day[purchase_day\u0026gt;0].describe(percentiles=(0.01,0.1,0.25,0.75,0.9,0.99)).T 消费了两次及以上的客户有50%的消费周期为7天内,用户的消费周期还是比较短的。75%为26天内，消费周期适中\n3.2.6新用户、不活跃用户、回流客户、活跃客户情况 pivoted_cnt = df[df['amount']\u0026gt;0].pivot_table(index='user_id', columns='month', values='buy_cnt' aggfunc='sum').fillna(0) columns_month=pivoted_cnt.columns.astype('str') pivoted_cnt.columns=columns_month pivoted_purchase=pivoted_cnt.applymap(lambda x:1 if x\u0026gt;0 else 0) pivoted_amount.head(6) 对新用户、不活跃用户、回流客户、活跃客户的定义 若本月没有消费： 是第一个月，将客户标记为‘未注册’ 不是第一个月： 上个月‘未注册’，本月也‘未注册’ 上个月‘不活跃’，本月‘不活跃’ 若本月消费了： 是第一个月，标记为‘新客户’ 不是第一个月： 上个月不活跃，这个月‘回流’ 上个月‘未注册’，这个月‘新客户’ -上个月‘活跃’，这个月‘活跃’ 根据以上定义，可以写下面的函数：\ndef active_status(df): status=[] #代码定义了一个空的列表 status，用于存储每个月的客户活跃状态 for i in range(11): #通过一个循环从0到10（代表11个月，因为列的索引从0开始）遍历每个月的数据 #若本月没有消费 if df[i]==0: if len(status)\u0026gt;0: #如果不是第一个月 if status[i-1]=='未注册‘: #如果上个月已经是未注册，那么本月也是未注册 status.append('未注册') else: #如果上个月已注册，则本月为不活跃 status.append('不活跃') else: status.append('未注册') else: if len(status)==0: status.append('新客户') else: if status[i-1]=='不活跃': #如果上月为不活跃，则本月为回流 status.append('回流') elif status[i-1]=='未注册': #如果上月为未注册，那么本月为新注册 status.append('新客户') else: #如果上月为活跃，本月也活跃 status.append('活跃') return pd.Series(status,index=columns_month) pivoted_purchase_status = pivoted_purchase.apply(lambda x:active_status(x),axis=1) pivoted_purchase_status.head(5) purchase_user_cnt=pivoted_purchase_status.apply(lambda x: x.value_counts()) purchase_user_cnt=purchase_user_cnt[purchase_user_cnt.index !='未注册'] purchase_user_cnt=purchase_user_cnt.fillna(0) purchase_user_cnt=purchase_user_cnt.loc[['新客户','回流','活跃','不活跃'],:] purchase_user_cnt ax5=purchase_cnt.T.plot(figsize=(16,8)) ax5.set_ylabel('客户数量') ax5.set_xlabel('月份') ax5.set_title('各月份用户活跃数量分析') 3.2.7RFM模型构建 R：最近一次消费（Recency） F：消费频率（Frequency） M：消费金额（Monetary） 按照下面代码构建RFM模型\nuser_rfm=df.groupby(['user_id','date']).agg(消费金额=('amount','sum')).reset_index() user_rfm=user_rfm.groupby('user_id').agg(最后购买日期=('date','max'),M=('消费金额','sum'),F=('date','count')).reset_index() user_rfm['最后购买日期'] = pd.to_datetime(user_rfm['最后购买日期']) user_rfm['R'] = user_rfm['最后购买日期'].apply(lambda x:user_rfm['最后购买日期'].max() - x) user_rfm['R'] = user_rfm['R'].dt.days user_rfm=user_rfm[['user_id','R','F','M']] #R的打分: #[0-30]:5分 #(30-60]:4分 #(60-90]:3分 #(90-120]:2分 #120以上:1分# #F的打分: #1次:1分 #2次:2分 #3次:3分 #4次:4分 #5次及以上:5分 #M的打分: #[0-200]:1分 #(200-500]:2分 #(500-1000]:3分 #(1000-2000]:4分 #2000以上:5分 rfm_score = user_rfm.copy() for i,j in enumerate(rfm_score['R']): if j \u0026lt;= 30: rfm_score['R'][i] = 5 elif j \u0026lt;= 60: rfm_score['R'][i] = 4 elif j \u0026lt;= 90: rfm_score['R'][i] = 3 elif j \u0026lt;= 120: rfm_score['R'][i] = 2 else : rfm_score['R'][i] = 1 for i,j in enumerate(rfm_score['F']): if j\u0026lt;=1: rfm_score['F'][i]=1 elif j\u0026lt;=2: rfm_score['F'][i]=2 elif j\u0026lt;=3: rfm_score['F'][i]=3 elif j\u0026lt;=4: rfm_score['F'][i]=4 else: rfm_score['F'][i]=5 for i,j in enumerate(rfm_score['M']): if j \u0026lt;= 200: rfm_score['M'][i] = 1 elif j \u0026lt;= 500: rfm_score['M'][i] = 2 elif j \u0026lt;= 1000: rfm_score['M'][i] = 3 elif j \u0026lt;= 2000: rfm_score['M'][i] = 4 else : rfm_score['M'][i] = 5 rfm_score.head() rfm = pd.DataFrame() rfm['user_id'] = rfm_score['user_id'] rfm['R'] = rfm_score['R'].apply(lambda x: '1' if x \u0026gt;= rfm_score['R'].mean() else '0') rfm['F'] = rfm_score['F'].apply(lambda x: '1' if x \u0026gt;= rfm_score['F'].mean() else '0') rfm['M'] = rfm_score['M'].apply(lambda x: '1' if x \u0026gt;= rfm_score['M'].mean() else '0') rfm['result'] = rfm['R'] + rfm['F'] + rfm['M'] for i,j in enumerate(rfm['result']): if j == '111': rfm['result'][i] = '重要价值客户' elif j == '101': rfm['result'][i] = '重要发展客户' elif j == '011': rfm['result'][i] = '重要保持客户' elif j == '001': rfm['result'][i] = '重要挽留客户' elif j == '110': rfm['result'][i] = '一般价值客户' elif j == '100': rfm['result'][i] = '一般发展客户' elif j == '010': rfm['result'][i] = '一般保持客户' elif j == '000': rfm['result'][i] = '一般挽留客户' rfm = rfm[['user_id','result']] rfm['result'].value_counts() plt.figure(figsize=(16,8)) plt.bar(rfm['result'].value_counts().index,rfm['result'].value_counts().values) for x,y in enumerate(rfm['result'].value_counts()): plt.text(x,y+100,y,ha='center') plt.show 重要的客户共有44129人 其中重要价值客户有20012人,约占重要客户的50%,对于重要价值客户,要给与他们VIP式的服务,时刻留意他们的购买反馈 重要发展客户有4415人,这类客户消费频率不够高,要想办法提高他们的消费频率,例如发放满减卷等 重要保持客户有11368人,这类客户最后一次购买时间距离现在已经很远了,应该发送信息,或者电话联系他们,也可以发放满减卷给他们,提高他们的复购率 重要挽留客户有8334人,要想办法挽回这批将近流失的客户,也可以通过短信召回,发放优惠券. 评论 一般的客户共有48626人 对于一般价值、一般发展、一般保持的客户,在处理好重要客户的情况下，可以酌情去发展维系这批客户。 其中一般挽留用户有26843人,这类客户是要流失的,所以在没有多余资源的情况下,就放弃这批客户吧。 ","permalink":"https://vickycyq.github.io/zh/posts/project/%E7%94%B5%E5%95%86%E9%94%80%E5%94%AE%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/","summary":"用户分析方法论及结论 用户分析方法论 结论 1.数据总览 import pandas as pd import numpy as np import matplotlib.pyplot as plt from datetime import datetime #忽略警告 import warnings warnings.filterwarnings('ignore') plt.rcParams['font.sans-serif'] = ['Heiti TC'] # 指定中文字体，例如使用中文宋体：","title":"python用户分析数据可视化"},{"content":"\u0026ldquo;Zero-Shot Prompting\u0026quot;也称为“零样本提示”，是指在机器学习和自然语言处理中的一种技术，用于解决模型在处理未曾见过的、未经训练的类别或者数据时的问题。传统的机器学习模型需要在训练阶段接触到每个类别的数据样本，然后才能对其进行分类或者执行其他任务。但是，通过零样本提示，模型可以利用先前学习到的知识来完成该任务。\n例如，在自然语言处理中，如果模型已经训练了大量词汇，但是在测试的时候遇到了一个新的词汇，零样本提示可以让模型通过词汇的词义、上下文或者其他信息来推测该新词汇的含义，而不需要提供新词汇的训练样本。\n以下是零样本提示的使用示例：\n将文本分类为中性、负面、正面。 文本： 就这么点，不知道的还以为我要求的。少得可怜，我自己做都比这个多，这么点东西好意思收我60。 情感： ChatGPT输出：\n根据提供的文本，可以将其情感分类为负面。 这段文本表达了对某项要求的不满和对提供的服务或产品的不满意。 在这个例子中，我没有告诉ChatGPT什么样的文本是中性、负面或者正面，但是ChatGPT能正确对文本进行分类。\nWei et al.(2021)的研究采用了一个包含1370亿个参数的预训练模型，并在60多个自然语言指令模版下描述的NLP数据集上进行了instruction tune,并将instruction-tuned model称为FLAN。从下面的图片可以看出，instruction-tuning能有效提高语言模型的zero-shot学习能力。\nInstruction-tuning是一种微调大型预训练语言模型的方法，可以让模型根据特定任务提供指令来执行任务。 Fine-tuning和instruction tuning以及Prompt-tuning的区别：\nFine-tuning 是指采用预训练的模型（通常是在大规模数据上进行预训练的模型，如BERT、GPT等）作为初始模型，然后在特定任务的小规模数据上进行进一步训练。这种方法允许将大型通用模型迁移到特定任务上，以适应特定的数据和任务需求。 Instruction tuning模型不仅接受任务数据，还接受一种被称为\u0026quot;指导\u0026quot;或\u0026quot;说明\u0026quot;的自然语言输入，以帮助模型更好地适应特定任务。 Prompt tuning中，任务描述或提示文本（prompt）被设计成模型输入的一部分,是一种用于改善任务性能的技术,通常用于问答和文本生成任务。 Fine-tuning 是一种通用的微调方法，而instruction tuning 是fine-tuning 的一种变种，它利用自然语言指导来指导模型在特定任务上的微调，从而提高模型的性能。Instruction tuning 的关键优势在于它可以更灵活地适应多样的任务和指导。 当零样本提示不起作用时，可以适当在提示中提供演示或者示例，这种提示方式称为少样本提示。下一节将介绍少样本提示。\n","permalink":"https://vickycyq.github.io/zh/posts/read/prompt-engineering/2-%E6%96%87%E6%9C%AC%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8A%80%E6%9C%AF/1-%E9%9B%B6%E6%A0%B7%E6%9C%AC%E6%8F%90%E7%A4%BA/","summary":"\u0026ldquo;Zero-Shot Prompting\u0026quot;也称为“零样本提示”，是指在机器学习和自然语言处理中的一种技术，用于解决模型在处理未曾见过的、未经训练的类别","title":"Zero-Shot Prompting"},{"content":" 战略决策主题规划复盘与思考 方法论： 通过企业《市场洞察及策略研讨资料》、《年度经营计划》、《年度预算编制》、季度经营分析会议材料等厘清企业战略决策全生命旅程的各个环节，结合 “五看三定” 模型以及DSTE框架对各个环节进行关键绩效指标梳理，根据关键绩效指标形成业务分析主题看板 管理驾驶舱规划可结合公司战略目标按照价值链排列方式设计，在数据监控过程中可沿着价值链方向根据数据异常发现业务问题 复盘与思考： 在项目实施过程中发现某个目标（指标A）设置的数值不合理。在与一线业务人员沟通的过程中发现，业务人员如果把精力放在完成指标A上，以指标A的目标数量，如果人员安排合理，指标B的数量将会是现在的目标的4倍。但是按照企业目前的情况，指标B的完成应该放在第一位，并且年度完成的结果可能只是指标B目标的一点几倍。显然指标A设置的数值过高，一线业务人员如果要完成指标A必然需要耗费大量精力，而无暇顾及目前集团最重视的指标B，企业应该理清指标A与指标B之间的关系，降低指标A的目标，让一线业务人员在完成指标B的情况下也能完成指标A 1. 战略决策业务框架及业务闭环思路 通过拆解战略决策全生命旅程，结合华为“五看三定”模型以及DSTE框架，构建战略决策业务分析框架，对各个环节分析内容展开，形成战略决策主题分析框架 1.1 战略决策全生命旅程 战略规划 市场洞察 战略分析与规划 经营执行与评估 经营目标 经营策略 经营计划 经营预算 绩效考核 1.2 五看三定 战略洞察 通过五看的方式（看宏观、看市场、看用户、看竞争、看自己），分析消费趋势，寻找与竞争对手的差距点以及行业机会点。（注：华为原五看为看行业/趋势、看市场/客户、看竞争、看自己、看机会，根据实际情况修改） 宏观环境分析（PEST为经典模型，但可根据实际情况增删内容）： 经济分析：通过GDP、投资、零售、货币政策等重点指标分析经济发展周期，查看经济周期与该行业发展周期的关系；根据当前经济周期调整长期战略；例如繁荣期扩大市场份额和投资，衰退期降本增效 消费分析：通过通货膨胀（CPI）=M2增速-GDP增速、CPI、PPI指标，分析经济热度；通过对比CPI与产品价格，分析经济热度，指导公司明确未来价格提升幅度与策略（跑赢通胀是基础），尤其是高端产品 收入分析：各省人均可支配收入情况，人均可支配收入增速，同时对比该区域订单收入增速；通过分析各省市经济状况和销售形势与方向，重点关注订单收入增速落后区域 人口分析：通过分析人口及其年龄结构变化，分析适饮/吃/用人口数量变化趋势根据年龄结构有助于产品目标市场定位、店铺选址、广告和宣传策略等 行业分析： 市场分析：通过波士顿矩阵查看公司/品牌在市场中的位置，根据分析结果分配资源或者制定不同产品的战略定位；或者通过价格带分析不同价格带产品/品牌市场份额或者订单收入或者其他指标、同比增速等等，洞察哪个价格带未部署产品或者哪个价格带有更大的切入机会；进一步对优势品牌进行分析，以寻找本品与竞品差异点 消费者分析：通过研究消费者交互数据、人口数据、行为数据、交易数据等挖掘消费者的关注点，从而找到产品差异化机会点 竞争态势分析：可使用波特五力模型作为研究框架，结合行业集中度、竞争对手的市场概况、商业模式、产品策略等，寻找本品与竞品差异点，看是否有新的商业机会 内部分析：通过对内部产品经营状况分析、产品竞争力以及内部运营分析，寻找内部优势，例如技术优势等 战略分析与规划 通过“三定”的方式（定控制点、定目标、定策略）制定企业战略规划； 战略控制点：指公司核心竞争力所在，这种竞争优势很难轻易形成，竞争对手也难以轻易赶上。比如成本优势、性能和品质的领先、绝对的市场份额、专利技术等； 定目标：达标目标（自上而下）+挑战目标（自下而上）； 定策略：制定具体方案和阶段里程碑、实施策略 战略分解 战略分解也称为战略解码，指的是分析和理解一个组织、企业或项目的战略计划、愿景和目标，以便将这些战略目标转化为具体的行动步骤和决策，战略解码工作可以采用BEM（Business strategy execution model）业务战略执行模型进行 BEM通过对战略逐层逻辑解码，导出可衡量和管理战略的KPI以及可执行的重点工作和改进项目/任务，并采用系统有效的运营管理方法，确保战略目标达成。BEM方法核心是PDCA模型，通过PDCA确保规划可落地 1.3 DSTE框架 DSTE概念：全称Develop strategy to execution，从战略到执行 战略规划流程（SP，Strategy Plan） 明确战略及战略描述：战略是为了牵引组织达成中长期目标的一系列行动而给出的指导方向性的、全局的谋略，是基于对未来的判断。对战略的描述应该具体可衡量。这一步可以使用BLM模型导出。 识别中长期关键战略举措（KSF）:根据业务要求，系统性分析战略布局，找出影响战略成功的关键因素，概括战略实现的具体措施 通过对商业模式的正确定义，应用Business Model Canvas设定战略方向，并进行mapping。商业模式描述了企业如何创造价值，传递价值和获取价值的基本原理 战略地图：描述组织如何创造价值，为战略制定和战略执行之间的鸿沟搭起一座桥梁。战略地图是平衡计分卡基础上发展而来的，是以平衡计分卡的四个层面目标（财务层面、客户层面、内部层面、学习层面）为核心，通过分析这四个层面目标的相互关系而绘制的企业战略因果关系图 导出战略衡量指标：可以使用IPOOC方法 年度业务规划（BP，Business Plan） 确定年度关键业务举措及目标：年度业务关键措施是指从客户与经营角度，为了支持战略达成的当年业务需要改进的关键点，业务关键措施针对业务和短板/痛点可能每年有所不同 分解年度关键业务举措和目标：沿着流程或者部门，将一层组织的业务关键措施和目标分解到下级部门，并从上至下，确定各层衡量指标的基线和目标值 确定年度重点工作：年度重点工作指的是关键战略措施在当年的具体措施，包括行动、阶段性目标、责任部门，是优先的工作任务 基于年度业务关键措施和目标拉通整合形成重点工作，设定工作目标及owner； 重点工作描述是针对战略举措要在当年落地的工作 重点工作目标主要承接战略举措在第一年的目标、组织KPI指标，从上至下结构化分解，确定各层衡量指标和值 战略执行监控与战略评估 战略执行监控 战略目标管理工具：为了战略有效得到执行和闭环，在组织绩效目标中设置“战略目标”，牵引各组织加强对战略机会点的有效投入，对当期业务结果负责的同时要对中长期持续发展负责 运营仪表盘工具：掌握SP/BP落地情况，并进行闭环管理 ","permalink":"https://vickycyq.github.io/zh/posts/blog/%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%9B%98%E4%B8%8E%E6%80%9D%E8%80%83/%E6%88%98%E7%95%A5/","summary":"战略决策主题规划复盘与思考 方法论： 通过企业《市场洞察及策略研讨资料》、《年度经营计划》、《年度预算编制》、季度经营分析会议材料等厘清企业战略","title":"战略决策分析框架建立与思考"},{"content":"在完成更复杂的任务时，零样本提示表现不佳，此时可以使用少样本提示（few-shot prompting），启用in-context learning，通过为模型提供demonstration引导模型实现更好的性能。\n“Few-Shot Learning\u0026quot;是指机器学习或深度学习中的一种训练策略，其中模型在处理训练数据时只使用非常有限数量的样本或示例。模型通过仅使用少量样本来学习任务，从而更好地泛化到未见过的数据。这对于许多应用场景非常重要，特别是在数据稀缺的情况下，例如医疗诊断、自然语言处理中的语言翻译等领域。 “Few-Shot Prompting\u0026quot;是一种用于预训练语言模型的技术，旨在将模型引导到执行特定任务的方式.“少样本”通常表示提示的信息非常有限，但是模型能根据这个提示来生成答案或执行任务. zero-shot和one-shot对比示例：\n输入：\n请用farduddle这个词造句 ChatGPT输出：\n他在寒风中等待了一个小时，完全感到了冷到了骨子里，但他坚持在那里farduddle着，直到朋友终于出现了。 可以看出，ChatGPT并没有理解这个单词，因此造出来的句子词不达意。接下来用 Brown et al.（2020）的例子做one-shot prompting。 输入：\n“whatpu”是坦桑尼亚的一种小型毛茸茸的动物。一个使用whatpu这个词的句子的例子是： 我们在非洲旅行时看到了这些非常可爱的whatpus。 “farduddle”是指快速跳上跳下。一个使用farduddle这个词的句子的例子是： ChatGPT输出：\n孩子们在操场上高兴地farduddle着，玩得不亦乐乎。 在这个例子中，我们给了ChatGPT一个demonstration，ChatGPT已经能根据给的demonstration执行任务，对于更困难的任务，可以增加demonstration的个数（5-shot, 10-shot）。\nZhao et al.(2021)的论文指出：\ndemonstration的format很重要，即使只是使用随机标签，模型的performance也比没有标签好 demonstration的input的分布对模型的in-context learning性能影响很大，而label space的分布则不重要 而另一篇论文则有不完全相同的研究结论，Min et al., (2022)的论文则指出：\nlabel space和demonstration的输入文本的分布都很重要（标签是否正确） 使用的格式也对性能起着关键作用，即使只是使用随机标签，这也比没有标签好得多 其他结果表明，从真实标签分布（而不是均匀分布）中选择随机标签也有帮助 我们给下面的外卖评论分配随机标签，看ChatGPT能否正确完成任务： 输入：\n这家分店的五分糖巨甜！！！比我喝过的其他店的都甜很多//负面 今天的要么太咸，要么太淡，牛肉还没烤干，都丢了没吃//正面 吃过很多次了，连带淄博小饼套餐，很喜欢烤牛肉和鸡翅//负面 记不清第几次点了，好吃太好吃了，简直是本干饭人心中的白月光// ChatGPT输出：\n最后一个评论非常正面，表达了对食物的喜爱。 可以看出，即使给评论分配错误的标签，ChatGPT还是正确完成了任务\n执行更复杂的任务时，少样本提示的作用不大 输入：\nA、B是两个长方体物块，叠放在水平地面C上，A叠放在B上，F是作用在物块B上沿水平方向右的力，大小为200N，物块A和B以相同的速度做匀速直线运动，由此可知，关于A、B间摩擦力F1为0N，B、C间摩擦力为200N。 A：答案是True 水平地面上叠放A、B两个物体，A在B上面，A、B大小一样，给A施加一个向右的拉力F1=5N，给B施加一个向左的拉力F2=3N，那么物体B的上下表面所受到摩擦力的大小为5N和3N A：答案是False 水平面上叠放着A、B两个物体，A在B上面，在水平方向力F的作用下，相对静止，一起向左做匀速直线运动，已知F=5N，物体B上下表面所受摩擦力分别是5N和5N A： ChatGPT输出：\n在水平面上叠放A、B两个物体，它们以相同的速度做匀速直线运动，外力F=5N。因为它们以相同的速度运动，A、B之间的摩擦力应该平衡外力F，所以它们之间的摩擦力都是5N。这个陈述是True。 显然，ChatGPT给出了错误的答案，因为完成这个任务需要涉及更多的推理步骤，所以需要更高级的prompting技术，比如将步骤写成demonstration提示AI从而完成任务，下一节将介绍Chain-of-Though Prompting.\n","permalink":"https://vickycyq.github.io/zh/posts/read/prompt-engineering/2-%E6%96%87%E6%9C%AC%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8A%80%E6%9C%AF/2-%E5%B0%91%E6%A0%B7%E6%9C%AC%E6%8F%90%E7%A4%BA/","summary":"在完成更复杂的任务时，零样本提示表现不佳，此时可以使用少样本提示（few-shot prompting），启用in-context learni","title":"Few-Shot Prompting"},{"content":"\u0026ldquo;Chain-of-Thought Prompting\u0026quot;是指在demonstration中设计一系列连贯的思维步骤从而引导模型在面对复杂的推理任务时，将问题分解成多个中间步骤，并逐一解决，然后给出最后的答案。\n在CoT提出之前，关于大规模语言模型的推理任务中，有两种方法，一是针对下游任务对模型进行微调，但是微调成本高；二是为模型提供少量输入输出样例进行学习，传统的输入输出样例在推理任务上效果比较差。针对这个问题，Wei et al. (2022)提出Chain-of-Thought这种提示技术: 上图展示了few-shot prompting和chain of thought prompting方法求解推理任务的对比，few-shot prompting在推理任务中表现并不好 而CoT在demonstration中不仅给出了答案，还人为写出了中间的推理步骤。给出了根据CoT方式写的demonstration后，语言模型会自动先根据任务写出中间推理步骤，根据步骤给出正确答案 作者还在论文中提到了以下几点：\nCoT是将一个多步骤的复杂推理任务分解出中间步骤，而语言模型在输出的时候是一个一个token进行生成的，因此问题越难，步骤越多，生成的token数量就越多，因此越难的问题使用到的计算量就越大，计算机分配的计算资源也越多 在不知道答案的情况下，用CoT能同时知道中间推理步骤 接下来让我们使用CoT来解决上一节的推理问题： 输入：\nA、B是两个长方体物块，叠放在水平地面C上，A叠放在B上，F是作用在物块B上沿水平方向右的力，大小为200N，物块A和B以相同的速度做匀速直线运动，由此可知，关于A、B间摩擦力F1为0N，B、C间摩擦力为200N。 A：由于物块A和B以相同的速度做匀速直线运动，因此A受力平衡，合力为0，A不受摩擦力，所以A与B之间的摩擦力F1为0N；物块B受水平向右的力200N，同时以相同的速度做匀速直线运动，合力为0，因此物块B受水平向左的摩擦力200N，BC间的摩擦力为200N，答案是True 水平地面上叠放A、B两个物体，A在B上面，A、B大小一样，给A施加一个向右的拉力F1=5N，给B施加一个向左的拉力F2=3N，那么物体B的上下表面所受到摩擦力的大小为5N和3N A：由于物块A和B同时以相同的速度做匀速直线运动，因此A、B的合力均为0，A受向右的拉力5N，所以AB之间有向左的摩擦力5N；B受向左的拉力3N，向右的与A之间的摩擦力5N，因此B与地面之间的摩擦力是向左的2N，答案是False 水平面上叠放着A、B两个物体，A在B上面，在水平方向力F的作用下，相对静止，一起向左做匀速直线运动，已知F=5N，物体B上下表面所受摩擦力分别是5N和5N A： ChatGPT输出：\n对于第三个情况，答案可能是 False。物块 B 与地面之间的摩擦力应该受到施加在 B 上的力 F=5N 的影响，但具体的摩擦力大小取决于物块 B 和地面之间的摩擦系数。如果摩擦系数足够大，以至于可以平衡施加在 B 上的力 F=5N，那么 B 与地面之间的摩擦力可能为 5N。但如果摩擦系数较小，不能完全平衡力 F，那么摩擦力可能小于 5N。所以答案会取决于具体的摩擦系数值。 从上面的回答可以看出，ChatGPT给出了正确的答案，但是还是没有完全把A和B的受力情况答对。\nZero-shot-CoT：\n上面我们写的例子是mannual-CoT,即在输入问题前，手动设计一些问题和答案的样例，同时给出中间推理步骤，因此我认为在这种方式下，设计有代表性的样例和推理步骤比较重要。 而zero-shot-CoT就是在输入问题的时候，连接“let\u0026rsquo;s think step by step\u0026quot;让语言模型自动续写推理步骤，并最终生成答案。 我们看看以下例子：\n输入：\n水平面上叠放着A、B两个物体，A在B上面，B在水平方向力F的作用下，相对静止，一起向左做匀速直线运动，已知F=5N，物体B下表面与地面之间的摩擦力5N，A与B之间的摩擦力是0N，这是正确的吗？let's think step by step A： ChatGPT输出：\n物体 B 处于水平面上，所以有地面对物体 B 的支持力（垂直向上）以及重力（垂直向下）。由于物体 B 相对静止，这两个力必须平衡。 物体 B 与地面之间的支持力等于物体 B 的重力，这可以用牛顿的第三定律解释。支持力等于物体 B 对地面的作用力，也等于地面对物体 B 的反作用力，它们大小相等。 物体 B 在水平方向上受到外力 F=5N 的作用，这是一个向左的力。 由于物体 B 相对静止，水平方向上的外力 F 必须由摩擦力来平衡，以防止物体 B 滑动。 物体 A 在物体 B 上，如果 A 与 B 之间没有水平方向上的相对运动，那么它们之间的摩擦力应该是零。 综上所述，物体 B 下表面与地面之间的摩擦力是 5N，以防止它滑动，而 A 与 B 之间的摩擦力是零，因为它们之间没有相对运动。所以，这个情况是正确的。 从上面的例子可以看出，ChatGPT通过“let\u0026rsquo;s think step by step\u0026quot;这句话就能自动续写推理过程，并最终得出正确答案。在这个过程中，我曾修改了题目的描述，因此我认为清晰避免歧义的题目描述也有助于ChatGPT理解文本并按步骤推理。\nAuto-CoT：\nZhang et al.(2022)在论文中尝试使用Auto-CoT，即先把示例问题加上“let\u0026rsquo;s think step by step\u0026quot;这句话，让语言模型自动生成推理步骤，然后将示例加上生成的推理步骤以及答案拼接起来，构成few-shot样例，最后加上输入的问题让语言模型写中间推理步骤以及答案。 Active Prompt\n设计出针对特定任务的提示对语言模型生成高质量的答案的能力至关重要。从上文的研究可以看出，CoT prompting在针对复杂的问答推理任务时有比较好的表现，但是，目前的CoT方法依赖于人工标注的示例，而这些示例并不一定是适用于不同任务的最有效示例。因此，Diao et al.(2023)提出了一种名为Active-Prompt的方法。\n这种方法是指标来描述模型对每个问题预测的答案的不确定性，选出不确定性最大的一些问题，通过人工对这些问题用CoT的形式回答并加上测试问题输入语言模型，以提高语言模型的性能。例如：对于数据集D中的问题，输入语言模型，每个问题询问K次，然后计算基于这些问题的回答的 uncertainty。选出uncertainty最大的n个问题，并且对这些问题人工标注答案，作为example。然后用这些example加到每个测试问题中，按照CoT的方法提示。 对于uncertainty的衡量，论文给出以下四点： Disagreement：询问k次生成的k个答案中，相同答案出现的次数h的占比，即u=h/k Entropy：用下图的公式计算，熵越大，不确定性越大 Variance： Self-Confidence： 下图是实验结果： 从上图的实验结果可以看出来，跟baseline model相比，Active-Prompt这种方法让模型的performance更好了。 Self Consistancy Wang et al.(2023)在论文中提出了一种名为”Self Consistancy“的decoding策略来取代CoT方法的naive greedy decoding。\nNaive greedy decoding是一种简单且直接的解码方法，通常用于生成式任务。在这种解码方式中，模型会根据当前的输入和已生成部分的输出，选择概率最高的下一个单词或者符号作为预测结果，它只考虑当前最高的概率的单词或者符号，而不考虑后续的选择如何影响整体生成序列的质量，因此不能保证生成的整体序列在语法或者语义上是合理的。 从上图可以知道，self consistancy有三个步骤： （1）用CoT提示语言模型 （2）从语言模型的解码器中采样，生成一系列不同的推理路径 （3）剔除推理路径，在最终答案中选择最一致的答案 从上图结果可以看出，self consistancy的performance比CoT好。 我们来用这种方法试试前面提到的例子： 输入：\n1.水平面上叠放着A、B两个物体，A在B上面，B在水平方向力F的作用下，相对静止，一起向左做匀速直线运动，已知F=5N，物体B下表面与地面之间的摩擦力5N，A与B之间的摩擦力是0N，这是正确的吗？ A：物体 B 处于水平面上，所以有地面对物体 B 的支持力（垂直向上）以及重力（垂直向下）。由于物体 B 相对静止，这两个力必须平衡。 物体 B 与地面之间的支持力等于物体 B 的重力，这可以用牛顿的第三定律解释。支持力等于物体 B 对地面的作用力，也等于地面对物体 B 的反作用力，它们大小相等。 物体 B 在水平方向上受到外力 F=5N 的作用，这是一个向左的力。 由于物体 B 相对静止，水平方向上的外力 F 必须由摩擦力来平衡，以防止物体 B 滑动。 物体 A 在物体 B 上，如果 A 与 B 之间没有水平方向上的相对运动，那么它们之间的摩擦力应该是零。 综上所述，物体 B 下表面与地面之间的摩擦力是 5N，以防止它滑动，而 A 与 B 之间的摩擦力是零，因为它们之间没有相对运动。所以，这个情况是正确的。 2.水平地面上叠放A、B两个物体，A在B上面，A、B大小一样，给A施加一个向右的拉力F1=5N，给B施加一个向左的拉力F2=3N，那么物体B的上下表面所受到摩擦力的大小为5N和3N A：由于物块A和B同时以相同的速度做匀速直线运动，因此A、B的合力均为0，A受向右的拉力5N，所以AB之间有向左的摩擦力5N；B受向左的拉力3N，向右的与A之间的摩擦力5N，因此B与地面之间的摩擦力是向左的2N，答案是False 3.A、B是两个长方体物块，叠放在水平地面C上，A叠放在B上，F是作用在物块B上沿水平方向右的力，大小为200N，物块A和B以相同的速度做匀速直线运动，由此可知，关于A、B间摩擦力F1为0N，B、C间摩擦力为200N。 A： ChatGPT输出1：\n对于第三个情况，让我们仔细考虑一下： 物块 B 受到水平方向上的外力 F = 200N 的作用，这是一个向右的力。 物块 B 处于水平面上，所以有地面对物块 B 的支持力（垂直向上）以及重力（垂直向下）。由于物体 B 相对静止，这两个力必须平衡。 物块 B 与地面之间的支持力等于物块 B 的重力，这可以用牛顿的第三定律解释。支持力等于物体 B 对地面的作用力，也等于地面对物体 B 的反作用力，它们大小相等。 由于物体 B 相对静止，水平方向上的外力 F 必须由摩擦力来平衡，以防止物体 B 滑动。 所以，在这个情况下，物体 B 与地面之间的摩擦力应该是 200N，而物体 A 与 B 之间的摩擦力是 0N，因为它们之间没有相对运动。所以，这个情况是正确的。 ChatGPT输出2：\n水平面上叠放着 A、B 两个物体，A 在 B 上面，B 在水平方向受力 F 的作用下，相对静止，一起向左做匀速直线运动，已知 F=5N，物体 B 下表面与地面之间的摩擦力是 5N，A 与 B 之间的摩擦力是 0N。 物体 B 处于水平面上，所以有地面对物体 B 的支持力（垂直向上）以及重力（垂直向下）。由于物体 B 相对静止，这两个力必须平衡。 物体 B 与地面之间的支持力等于物体 B 的重力。 物体 B 在水平方向上受到外力 F=5N 的作用，这是一个向左的力。 由于物体 B 相对静止，水平方向上的外力 F 必须由摩擦力来平衡，以防止物体 B 滑动。 物体 A 在物体 B 上，如果 A 与 B 之间没有水平方向上的相对运动，那么它们之间的摩擦力应该是零。 综上所述，物体 B 下表面与地面之间的摩擦力是 5N，以防止它滑动，而 A 与 B 之间的摩擦力是零，因为它们之间没有相对运动。所以，这个情况是正确的。 ChatGPT输出3：\n让我们来分析第三种情况，即 A、B、C 三个物块的摩擦力情况： 物块 B 受到水平方向上的外力 F = 200N 的作用，这是一个向右的力。 物块 B 处于水平面上，所以有地面对物体 B 的支持力（垂直向上）以及重力（垂直向下）。由于物体 B 相对静止，这两个力必须平衡。 物块 B 与地面之间的支持力等于物块 B 的重力，这可以用牛顿的第三定律解释。支持力等于物体 B 对地面的作用力，也等于地面对物体 B 的反作用力，它们大小相等。 由于物体 B 相对静止，水平方向上的外力 F 必须由摩擦力来平衡，以防止物体 B 滑动。 关于摩擦力： A 与 B 之间的摩擦力：因为 A 和 B 相对静止，所以它们之间的摩擦力必须平衡外力 F。这意味着 A 和 B 之间的摩擦力应该是 200N，与外力 F 相等，以保持静止。 B 与 C 之间的摩擦力：由于 B 与 C 之间没有相对运动，它们之间的摩擦力应该是零。如果没有相对滑动，就不需要摩擦力来抵消外部力。 综上所述，关于 A、B 间的摩擦力 F1 为 200N 是正确的，而 B、C 间的摩擦力为 0N 也是正确的。 为了简单起见，我只用这个例子让ChatGPT输出3次，不同的推理步骤可以得到大多数一致的答案。\nMultimodal Chain-of-Thought\n现有的关于CoT的研究主要集中在language modality上，Zhang et al., (2023)提出将语言（文本）和视觉（图片）整合到一个两阶段的框架中，第一阶段是通过给模型输入文本和图片，模型根据输入内容输出中间推理过程；第二阶段是输入包含推理过程的问题文本以及图片，模型根据输入内容对结果进行推断。下图是Multimodal Chain-of-Thought这种方法的过程： 下图是实验结果： ","permalink":"https://vickycyq.github.io/zh/posts/read/prompt-engineering/2-%E6%96%87%E6%9C%AC%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8A%80%E6%9C%AF/3-cot_prompting/","summary":"\u0026ldquo;Chain-of-Thought Prompting\u0026quot;是指在demonstration中设计一系列连贯的思维步骤从而引导模型在面对复杂的推理任务时，将问题分解成多","title":"Chain-of-Thought Prompting"},{"content":"Liu et al.(2022)的论文提出了“知识生成提示”这种方式，主要做法是（1）先用few-shot demonstration的方式从语言模型中生成与问题相关的知识，然后（2）使用第二个语言模型对每个知识进行预测，然后选择置信度好的预测。 下图是论文的结果： 接下来我们用论文里面的例子来演示这种方式：\n首先，我们不用任何技巧，直接询问ChatGPT\n输入：\n高尔夫球的一部分是试图获得比其他人更高的得分。是或否？ 输出：\n是的，高尔夫球的一部分是试图获得比其他人更低的得分，因为在高尔夫中，较低的得分代表着更好的表现。 显然，ChatGPT的回答与后面的解释前后矛盾。 用知识生成提示方法：\n首先用few-shot的方法生成一些知识：\n输入：希腊比墨西哥大。 知识：希腊的面积约为131,957平方公里，而墨西哥的面积约为1,964,375平方公里，使墨西哥比希腊大了1,389%。 输入：眼镜总是会起雾。 知识：当你的汗水、呼吸和周围的湿度中的水蒸气落在冷的表面上，冷却并变成微小的液滴时，会在眼镜镜片上产生冷凝。你看到的是一层薄膜。你的镜片相对于你的呼吸会比较凉，尤其是当外面的空气很冷时。 输入：鱼有思考能力。 知识：鱼比它们看起来更聪明。在许多领域，如记忆力，它们的认知能力与或超过非人类灵长类动物等“更高级”的脊椎动物。鱼的长期记忆帮助它们跟踪复杂的社交关系。 输入：一个人一生中吸烟很多香烟的常见影响是患肺癌的几率高于正常水平。 知识：那些一生中平均每天吸烟不到一支香烟的人，患肺癌的风险是从不吸烟者的9倍。在每天吸烟1到10支香烟之间的人群中，死于肺癌的风险几乎是从不吸烟者的12倍。 输入：一块石头和一颗卵石大小相同。 知识：卵石是一种根据Udden-Wentworth沉积学尺度的颗粒大小为4到64毫米的岩屑。卵石通常被认为比颗粒（直径2到4毫米）大，比卵石（直径64到256毫米）小。 输入：高尔夫球的一部分是试图获得比其他人更高的得分。 知识： 输出：\n高尔夫球的目标是以最少的杆数打完一组洞。一轮高尔夫球比赛通常包括18个洞。每个洞在标准高尔夫球场上一轮只打一次。每个杆计为一分，总杆数用于确定比赛的获胜者。 提示:\n问题：高尔夫球的一部分是试图获得比其他人更高的得分。是或否？ 知识：高尔夫球的目标是以最少的杆数打完一组洞。一轮高尔夫球比赛通常包括18个洞。每个洞在标准高尔夫球场上一轮只打一次。每个杆计为一分，总杆数用于确定比赛的获胜者。 解释和答案： 输出1（置信度非常高）：\n不是，高尔夫球的目标不是获得比其他人更高的得分。相反，目标是以最少的杆数打完一组洞。总杆数用于确定比赛的获胜者，而不是总得分。 答案2（置信度要低得多）：\n是的，高尔夫球的一部分是试图获得比其他人更高的得分。每个选手都试图以最少的杆数打完一组洞。总杆数用于确定比赛的获胜者，而不是总得分。得分最低的选手赢得比赛。 不过，在论文中作者也提到，在提示时加入外部知识这种方法的优势可能随着基础模型的规模和在更大量文本数据集上进行预训练而逐渐消失。\n","permalink":"https://vickycyq.github.io/zh/posts/read/prompt-engineering/2-%E6%96%87%E6%9C%AC%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8A%80%E6%9C%AF/5-generated-knowledge-prompting/","summary":"Liu et al.(2022)的论文提出了“知识生成提示”这种方式，主要做法是（1）先用few-shot demonstration的方式从语言模型中","title":"Generated Knowledge Prompting"},{"content":"1. 市场管理业务闭环框架 业务举措： 线索发现：确定年度重点工作项目，明确工作内容、工作目标和承接单位；管理关键任务，分析跟踪市场秩序，通过经销商、工作人员等提报，发现违规线索，通过系统数据异常发现线索 稽核执行：处理发现的违规线索，分配稽核任务；经销商或市场管理人员发现违反物流秩序销售情况，购买违约销售产品，进行取证；补充修正终端信息，对终端的产品（本品、竞品）的陈列数量和价格数据的采集，结合经销商出货裸价和出货政策，发现异常并形成终端评价；监督稽核费用规划、执行和报销过程中的资料是否合规；市场人员对经销商的库存盘点，并上报各产品实物库存，系统自动用实物库存和最近一次经销商填报的库存（上期期末） + 新增的订单入库– 新增的经销商出库进行对比，如果存在差异则预警提示，需要填报人员回复差异原因 违规处理：基于核查取证情况，生成评价、反馈异常，并根据相应标准进行违规认定；根据违规类型不同，进行违规处理，如调整配额、扣减保证金、整改经销商等；营销费用使用监督中通过结案表对违规案件进行复查结案 通过建立指标体系，对数据进行监控，监督市场健康情况、市场窜货、营销舞弊行为、库存动销检查 ","permalink":"https://vickycyq.github.io/zh/posts/blog/%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%9B%98%E4%B8%8E%E6%80%9D%E8%80%83/%E5%B8%82%E5%9C%BA%E7%AE%A1%E7%90%86/","summary":"1. 市场管理业务闭环框架 业务举措： 线索发现：确定年度重点工作项目，明确工作内容、工作目标和承接单位；管理关键任务，分析跟踪市场秩序，通过经销商","title":"市场秩序管理分析框架建立与思考"},{"content":"1. 产品管理业务框架 1.1 产品管理闭环管理思路 产品规划：通过对现有产品组合进行分析或者对市场洞察，确定新产品需求 行业分析： 市场趋势和增长率：了解所在行业当前趋势以及增长率，以确定新产品所在市场的吸引力 市场规模：估算市场的总体规模和潜在新粉市场规模 市场驱动因素：确定市场需求的主要因素，例如技术创新、法规变化、消费者趋势等等 供应链和分销渠道：了解行业的供应链结构以及产品在市场上的分销渠道 竞争格局：了解主要竞争对手，包括市场份额、定价策略、产品特点等 法规和合规性：了解行业的法规要求和合规性问题，确保新产品符合相关法规 市场分析： 目标市场：明确定义新产品目标市场，包括受众特征和需求 客户画像：创建详细的用户画像，包括喜好、需求、问题和行为，查看是否有新机会 市场细分：将市场细分，查看是否有客户群体的需求未被满足 市场需求：了解目标市场的需求，包括问题、购买动机等等 市场份额：估算竞争对手在目标市场中的市场份额 市场渗透策略：确定如何进入市场，包括定价、推广、分销策略 竞品分析： 主要竞争对手：主要竞争对手的茶您、定价、市场份额、品牌声誉 竞品特点：竞品产品特点，包括功能、质量、口味、包装等 竞争优势：竞争对手的优势劣势 定价策略：竞争对手的定价策略 市场反应：预测竞争对手采取的反应措施，以应对新产品的推出 产品需求管理： 确定产品概念（人货场）：消费者洞察（从消费者角度提出其内心所关注的问题）、利益点（产品描述）、产品置信理由（介绍产品的特点，怎样解决消费者的问题） 通过产品概念确定产品研发需求 产品生命周期管理： 产品测价、定价： 基于成本的定价：根据成本与利润率定价，这个方式决定了定价范围的下限 基于所提供的价值定价：关注客户的最大支付意愿，这种方式决定了定价范围的上限 需考虑细分市场的购买力 该产品的替代品是什么，产品提供给消费者的附加价值是什么（相比于替代品），消费者愿意为这些附加价值付多少钱 基于竞争的定价：竞争对手产品价格及消费者愿意支付的最大的价格 其他因素：交叉销售/捆绑销售，若能产生更多的整体利润，可考虑降低价格；不同版本实施差异化价格；低价争夺市场份额（考虑是否可以承受，可以承受多久） 新品上线：通过小范围测试获取市场对产品的初步反馈，然后对产品进行迭代优化 小规模试点 控制内试点 模拟市场测试 产品投放、运营、退市： 新品期：产品刚刚上新，没有流量基础，需要做产品推广以及基础数据维护 爬坡期：有了基础数据反馈，根据数据分析结果制定一系列推广方案，让销量快速上升 稳定期：产品获得流量，销量持续稳定，可优化成本 衰退期：需要出新品快速迭代，进行下一个循环 ","permalink":"https://vickycyq.github.io/zh/posts/blog/%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%9B%98%E4%B8%8E%E6%80%9D%E8%80%83/%E4%BA%A7%E5%93%81/","summary":"1. 产品管理业务框架 1.1 产品管理闭环管理思路 产品规划：通过对现有产品组合进行分析或者对市场洞察，确定新产品需求 行业分析： 市场趋势和增长率：了解所","title":"产品管理分析框架建立与思考"},{"content":"1. 经销商管理业务框架 业务举措： 经销商准入：根据招商计划和市场情况提报经销商，通过对经销商的资质进行背调审核，并与符合标准的经销商签订合同 经销商基于配额下订单打款，并进行提货配送； 基于经销商管理系统中的提报和扫码数据进行库存管理； 基于活动计划制定、渠道活动执行、活动资源管理、费用执行跟踪和活动成效跟踪进行活动管控； 年度进行客户分级管理，综合销售业绩和市场合规性表现进行奖惩 经销商退出清算：退出检查包括市场违规、库存、费用、货款及保证金清算、订单担保贷款等检查；退出流程结束后合同保证金退款 经销商资源配置：将资源定向投入经销商，实现精准投入，提升资源投入效益 2. 终端管理业务框架 业务举措： 终端拓展：在各种渠道下进行终端拓展，采集本竞品数据查看市场渗透，终端评级（规划等级），指导业务拜访重点方向 终端维护与发展：业代拜访，辅助终端发展。终端进销存、价格数据、消费者数据采集；终端客情维护，例如节庆礼赠；辅助维护消费者和企业关系，例如团购支持、企业拜访等；终端形象建设；终端积分奖励 终端沉没：终端交互监控、定期终端数据清理（沉没终端） ","permalink":"https://vickycyq.github.io/zh/posts/blog/%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%9B%98%E4%B8%8E%E6%80%9D%E8%80%83/%E6%B8%A0%E9%81%93%E7%AE%A1%E7%90%86/","summary":"1. 经销商管理业务框架 业务举措： 经销商准入：根据招商计划和市场情况提报经销商，通过对经销商的资质进行背调审核，并与符合标准的经销商签订合同 经销","title":"渠道管理分析框架建立与思考"},{"content":"1. 消费者会员分析体系 1.1 消费者会员闭环管理思路 通过梳理消费者生命周期及用户旅程，对用户生命周期每一阶段用户命名及定义，便于在系统中实现有效的数据集合，实现对消费者生命周期的管理与分析\n潜客：企业各内容营销渠道中计划触达的个体；或者关注了企业各个第三方渠道，接受品牌价值主张的，但是未购买未注册会员的个体 用户：指在企业自有的平台（如小程序）或第三方平台授权个人用户信息，拥有唯一账号的个体 顾客：指在公域或者私域下过单，有订单信息进入企业数据库，并且可以在数据中识别出个人信息的个体 会员：拥有账号并获得企业授权会员身份的个体 忠诚会员：发生复购的会员 超级会员：圈层裂变的原会员主体升级成为超级会员 1.2 消费者会员管理核心指标框架 2. 消费者会员运营分析体系 2.1 消费者画像 消费者画像：即对消费者信息标签化。通过收集与分析消费者社会属性、生活习惯、消费行为等数据，根据各属性差异分为不同类型，将新类型提炼形成用户画像。\n基于用户画像的标签信息，企业可以有针对性地更新产品，使产品更贴合用户需求 通过标签可以迅速找到某一类型的用户进行精准营销 \u0026ldquo;ta是谁\u0026rdquo;:对消费者的性别、年龄段、学历、城市、社会属性等进行分析，识别企业/品牌/产品整体消费者物理属性信息及画像情况，可以为品牌/产品营销策略或者品牌策略提供方向。 “ta喜欢什么“：对消费者的品牌偏好、礼品偏好、价格带偏好、规格偏好等进一步分析完善用户画像 “ta从哪买“：对消费者的信息渠道、入会渠道、购买渠道进行分析，识别企业/品牌/产品的消费者/会员的行为习惯及动因，为后续优化消费者触点提供判断决策支撑 后续策略：\n通过用户画像，找到不同类型的标准用户聚集的平台 根据平台的特点和投放方式，匹配到免费/付费的推广方式 策划不同类型的运营方式：拉新活动、激活活动、老用户维护活动、用户增值拓展活动等 执行方案 根据执行后数据反馈，调整策略，优化推广效果 2.2 消费者生命周期分析 引入期：这一时期主要目标是将潜在用户转化为产品新用户，可以通过广告投放、地推、老带新活动、分享裂变等方式拉新 成长期：这一时期主要目标是通过各种策略提升用户留存及交易，可以通过收集用户反馈，提高产品体验、推出新产品等帮助用户转化 成熟期：通过交叉促销活动、社群运营、设置会员成长体系、优化核心产品功能等方式满足用户需求，提升用户粘性和交易 休眠期\u0026amp;流失期：这一时期主要目标是通过一些运营策略来预警和挽回用户，激活这部分沉默用户。通过数据判断这部分用户的体量，通过短信或者电话触达用户 2.3 会员资产与洞察 核心发展 重要保持客户、重要发展客户、重要挽留客户的数量，并且将他们不断转化为重要价值客户 重要保持客户：这种客户是最近消费时间比较远，但是消费金额和消费频次都很高，是一段时间没来消费的忠诚客户，应该主动保持联系，召回忠诚客户 重要发展客户：最近消费时间比较近，消费金额高，但是消费频次不高，说明这类客户忠诚度不高，应该在这类客户消费过程中保证服务体验，培养客户成为忠诚客户 重要挽留客户：最近消费时间比较远，消费频次不高，但是消费金额比较高，这类用户即将流失，应该联系客户，分析业务问题，改进问题并对客户予以挽留 在会员运营过程中，可结合RFM模型或者其他体现会员价值的模型、会员画像对不同类型的会员实施不同的运营策略，提高转化率\n会员生命周期分析：通过查看每月新增会员、活跃会员、沉睡会员、流失会员的数量分布，识别企业不同阶段会员运营情况，评估运营效果；通过对不同会员活跃情况，判断会员所处的生命周期阶段，根据不同阶段采取不同措施，例如如引导下单（新会员）、个性化推荐营销（活跃会员）、回归消费活动（沉睡会员）等 会员积分权益分析：对会员积分获取及使用情况进行分析，例如积分发放方式分布、积分新增及消耗趋势、会员等级积分分布等。通过对积分消费结构及趋势分析，可以灵活掌控用户积分发放，维持客户忠诚度，提升客户价值。 ","permalink":"https://vickycyq.github.io/zh/posts/blog/%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%9B%98%E4%B8%8E%E6%80%9D%E8%80%83/%E6%B6%88%E8%B4%B9%E8%80%85%E4%BC%9A%E5%91%98/","summary":"1. 消费者会员分析体系 1.1 消费者会员闭环管理思路 通过梳理消费者生命周期及用户旅程，对用户生命周期每一阶段用户命名及定义，便于在系统中实现有效的数","title":"消费者会员分析框架建立与思考"},{"content":"结论 AIGC可在游戏生产端、游戏运营端以及玩家体验端全方位赋能游戏产业，帮助游戏企业实现降本增效，开发创新玩法，提高玩家在游戏过程中的各项体验； 科技大厂收购游戏公司，纷纷入局游戏行业，通过自身AI技术与游戏公司行业经验结合，探索并加速AI对游戏的赋能与改造； 各游戏公司迅速布局AI并推动AI技术在游戏领域落地，市场反应良好，用户接受度高； AIGC赋能食品饮料行业人-货-场全链条条，构筑沉浸式社会营销，帮助企业获得新的增长点； 目前AI+游戏模式仍存在技术挑战，主要是3D模型数据存在大量缺失，在外部数据训练中，小体量数据难以起到显著作用，因此大模型大厂正持续整合3D数据资产。 具体内容 ","permalink":"https://vickycyq.github.io/zh/posts/read/aigc/aigc+%E6%B8%B8%E6%88%8F%E5%9C%A8%E9%85%92%E6%B0%B4%E9%A5%AE%E6%96%99%E8%A1%8C%E4%B8%9A%E4%B8%AD%E5%BA%94%E7%94%A8%E7%9A%84%E7%A0%94%E7%A9%B6/","summary":"结论 AIGC可在游戏生产端、游戏运营端以及玩家体验端全方位赋能游戏产业，帮助游戏企业实现降本增效，开发创新玩法，提高玩家在游戏过程中的各项体","title":"AIGC+游戏在酒行业营销中的应用"},{"content":"","permalink":"https://vickycyq.github.io/zh/link/","summary":"","title":"🔗友链"}]